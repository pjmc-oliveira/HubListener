\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../../Comments}

\begin{document}

\title{HubListener: Verification \& Validation Plan} 
\author{Zed Ahmad, Prakhar Jalan, Pedro Oliveira, Piranaven Selvathayabaran}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
November,21 2018 & 1.0 & Template Setup\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

The symbols, abbreviations and acronyms used in this document include those defined in the table below. \newline
\renewcommand{\arraystretch}{1.2}

\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  MIS & Module Interface Specification\\
  MG & Module Guide \\
  TC & Test Case \\
  VnV & Verification and Validation\\
  \bottomrule
\end{tabular}\\


\newpage

\tableofcontents

\listoftables %if appropriate

\listoffigures %if appropriate

\newpage

\pagenumbering{arabic}

This document outlines the system verification and validation plan for the HubListener software. General information regarding the system under test and the objectives of the verification and validation activities are provided in Section 3.  Overviews of the verification plans for the SRS, design, and implementation are given in Section 4, along with a summary of the validation plan for the software. 


\section{General Information}

\subsection{Summary}
The software being tested is the open-source software, HubListener.  HubListener provides users with relevant metrics, trends, and
information regarding their GitHub project, and in some cases, push the user to make appropriate changes (can be organizational) that are intended to lean the project towards a more `successful' one.

\subsection{Objectives}
The purpose of the verification and validation activities is to confirm that HubListener exhibits the desired software qualities. The primary objective is to build confidence in the correctness of the software. The tests described in this document cannot definitely prove correctness, but they can build confidence by verifying that the software is correct for the cases covered by test. 
\subsection{References}

Information about the purpose and requirements of HubListener can be found in the SRS document. The latest documentation for HubListener can be found on GitHub:  \href{https://github.com/pjmc-oliveira/HubListener/}{HubListener}

\section{Plan}

\subsection{Verification and Validation Team}

The HubListener Team, which includes all the authors of this document will be responsible for the verification and validation of HubListener. Input from our supervisor, Dr.  Smith  will also contribute to the VnV Plan and he will ensure proper procedures take place. 

\subsection{SRS Verification}

SRS Verification will be carried out by reviews. The HubListener team will do two reviews. One review will take place on January 31st, 2019, the expected launch date of Version 1. A second review will occur at the launch date of Version 2 which will be determined at a later date. These reviews will be done as a collective in separate meetings to confirm theories and models in the SRS are correct. Any issues identified during this review will be noted down and new Issues on GitHub will be created. These issues will have top priority and will be completed in the next possible Sprint by one member of the HubListener team. This review will be followed up by additional reviews by Dr.  Spencer Smith and Dr.  Anand ( if he wishes). Again, any issues identified by these reviewers will be recorded through the issues tracker on GitHub. A focus of these reviews will be to verify the functional and non-functional requirements of correctness and understandability by identifying information from the SRS that is incorrect or ambiguous.   

\subsection{Design Verification Plan}

The design of HubListener will be outlined in the Module Guide (MG) and Module Interface Specification (MIS) documents. The design will be verified by review of these documents. Dr.  Smith will review this documents. To verify correctness, part of this review til be to ensure that every module traces to a requirement and that every requirement is traced to by a module. Any issues identified during this review will be noted down and new Issues on GitHub will be created. These issues will have top priority and will be completed in the next possible Sprint by one member of the HubListener team. Reviews of these design documents will also focus on ensuring the understandability  by identifying descriptions and specifications that are ambiguous. 

\subsection{Implementation Verification Plan}

The implementation of HubListener will be verified by review and by testing. The HubListener team will extensively review the implementation. This will be done via bi-weekly code-reviews. In the context of agile methodologies, every sprint, each member will be assigned code from a peers to review. This code is typically from the previous sprint. If the code passes code review, it will be merged into the master-branch. Any issues identified during this review will be noted down and new Issues on GitHub will be created. These issues will have top priority and will be completed in the next possible Sprint by one member of the HubListener team. These reviews will contribute to verifying correctness and understandability of the software by identifying code that is not traceable to any specifications described in the SRS , MG or MIS.
\newline

The implementation will also be verified through testing. Specific test cases are outline in Section 5 of this document. Test cases that are directly dependent on implementation details will be outlined at a later date. All tests will be written(where applicable), reviewed and executed by the HubListener Team. 

\section{System Test Description}
In this section, we will describe and define the tests for functional and non-functional requirements as well as for HubListener's design module.

\subsection{Tests for Functional Requirements }
This section will describe the test cases that will be used for testing the functional requirements.

\subsubsection{Valid User Input}
The following set of test cases are intended to cover different forms of valid user input 

\begin{enumerate}
\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
\end{enumerate}

\subsubsection{Requirements Testing}
The following set of test cases are intended to cover testing of each functional requirement 
\paragraph{Requirement 1}
\begin{enumerate}
\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
\end{enumerate}
\paragraph{Requirement 2}
\begin{enumerate}
\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
\end{enumerate}
\paragraph{Requirement 3}
...
\subsubsection{ Error Handling Testing}
The following set of test cases are intended to cover error handling situations. 
\begin{enumerate}
\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
\end{enumerate}

\subsection{Nonfunctional Requirements Evaluation}

\subsubsection{Usability Testing}
In this section, we will explore the manual test cases needed for testing usability. 
\begin{enumerate}
\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
\end{enumerate}
\subsubsection{Maintainability  Testing}
In this section, we will explore the manual test cases needed for testing  the maintainability of HubListener. 
\begin{enumerate}
\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
\end{enumerate}
\subsubsection{Performance Measurement}

In this section, we will explore the manual test cases needed for testing the performance of HubListener. 
\begin{enumerate}
\item{test-id1\\}

Control: Manual versus Automatic
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}
					
How test will be performed: 
\end{enumerate}
		
\subsection{Trace to Requirements}

Will include matrix here. The purpose of the traceability matrix is provide easy reference on which requirement are verified by which test cases,and which test cases need to be updated if a requirement changes. 
		
\subsection{Trace to Modules}		

In this section, a matrix will  be included to trace which modules are verified by which test cases, and which test cases need to be updated 

\section{Unit Testing}

Unit Testing will  be completed using either Mocha.js or Jasmine.js . Both tools provide the resources required to get thorough unit testing complete. We are still in the research phase and not have decided on a set tool. Jasmine.js remains the front-runner as one of members on the HubListener team has experience with this tool. 


\section{Automated Testing}

Automated testing will further enhance our testing efforts. We are investigating Travis-CI which  is a free web based service that allows  to register a trigger on GitHub so that every time a commit is pushed to GitHub an isolated Ubuntu container with the correct container that we want to test, builds the software (if needed) and then runs the test.


\section{Appendix}

This is where you can place additional information.

\subsection{Usability Survey Questions}
Here is where the Usability Survey Questions will go. 

\bibliographystyle{plainnat}

\bibliography{SRS}

\end{document}